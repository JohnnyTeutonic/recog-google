{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import albumentations\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Sequential, optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import BatchNormalization, Activation, Conv2D, Dense, Dropout, Flatten, GlobalMaxPool2D, MaxPooling2D, Softmax\n",
    "import keras\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('landmark-recognition-challenge/train.csv')\n",
    "OUTPUT_DIR  = 'output'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = glob.glob('output/' + '*.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not get file\n"
     ]
    }
   ],
   "source": [
    "arr_list = []\n",
    "lost_files = 0\n",
    "lost_names = []\n",
    "for file in os.listdir('output/'):\n",
    "    try:\n",
    "        img = io.imread('output/' + file)\n",
    "        input_arr = np.array([img])  # Convert single image to a batch.\n",
    "        inpur_arr = np.expand_dims(input_arr, axis=0)  # or axis=1\n",
    "        arr_list.append(input_arr)\n",
    "    except:\n",
    "        print('could not get file')\n",
    "        lost_files+=1\n",
    "        lost_names.append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = []\n",
    "for file in os.listdir('output'):\n",
    "    file_name, ext = os.path.splitext(file)\n",
    "    id_list.append(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = a[a.id.isin(id_list)]\n",
    "train_data = train_data[~train_data.id.isin(lost_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'output/'\n",
    "test_image_files = glob.glob(test_path + '*.jpg')\n",
    "test_image_ids = [image_file.replace(\n",
    "    '.jpg', '').replace(test_path, '') for image_file in test_image_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_ids.remove(os.path.splitext(*lost_names)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_info = a[a.id.isin(test_image_ids)]\n",
    "labels = label_encoder.fit_transform(train_info['landmark_id'].values)\n",
    "one_hot_encoder = OneHotEncoder(sparse=True, categories=train_data['landmark_id'].nunique())\n",
    "train_info['labels'] = label_encoder.fit_transform(train_info['landmark_id'].values)\n",
    "e = train_info['labels'].values.reshape(-1,1)\n",
    "onehot = pd.get_dummies(train_info['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = onehot\n",
    "#Y = Y[:-1]\n",
    "X = arr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train[0].shape[1], X_train[0].shape[2], X_train[0].shape[3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "#gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\n",
    "#custom_config=tf.compat.v1.ConfigProto(log_device_placement=True, allow_soft_placement=True)\n",
    "#custom_config.gpu_options.allocator_type = 'BFC'\n",
    "#custom_config.gpu_options.per_process_gpu_memory_fraction = 0.90\n",
    "\n",
    "#session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 600, 600, 16)      784       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 600, 600, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 600, 600, 16)      64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 300, 300, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 150, 150, 32)      4640      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 150, 150, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 38, 38, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 38, 38, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 19, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 5, 5, 128)         32896     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2259)              580563    \n",
      "=================================================================\n",
      "Total params: 769,667\n",
      "Trainable params: 769,187\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelBN = Sequential()\n",
    "modelBN.add(Conv2D(filters=16, kernel_size=4,strides=(2, 2), padding='same', use_bias=True, input_shape=input_shape))\n",
    "modelBN.add(Activation(\"relu\"))\n",
    "modelBN.add(BatchNormalization())\n",
    "modelBN.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "modelBN.add(Conv2D(filters=32, kernel_size=3, strides=(2, 2),padding='same', use_bias=True))\n",
    "modelBN.add(Activation(\"relu\"))\n",
    "modelBN.add(BatchNormalization())\n",
    "modelBN.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "modelBN.add(Conv2D(filters=64, kernel_size=3, strides=(2, 2), padding='same', use_bias=True))\n",
    "modelBN.add(Activation(\"relu\"))\n",
    "modelBN.add(BatchNormalization())\n",
    "modelBN.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "modelBN.add(Conv2D(filters=128, kernel_size=2, strides=(4, 4), padding='same', use_bias=True))\n",
    "modelBN.add(Activation(\"relu\"))\n",
    "modelBN.add(BatchNormalization())\n",
    "modelBN.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "modelBN.add(Flatten())\n",
    "modelBN.add(Dense(256, activation='relu'))\n",
    "modelBN.add(Dropout(0.3))\n",
    "modelBN.add(Dense(train_data['landmark_id'].nunique(), activation='softmax'))\n",
    "\n",
    "modelBN.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0e180933aa9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodelBN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adamax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizers' is not defined"
     ]
    }
   ],
   "source": [
    "adam = optimizers.Adam(lr=0.02)\n",
    "modelBN.compile(optimizer='adamax', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3190 samples, validate on 1064 samples\n",
      "Epoch 1/25\n",
      "3190/3190 [==============================] - 109s 34ms/step - loss: 7.4748 - accuracy: 0.0414 - val_loss: 7.4403 - val_accuracy: 0.0367\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.44031, saving model to saved_models/weights.best.from_BatchNorm.hdf5\n",
      "Epoch 2/25\n",
      "3190/3190 [==============================] - 107s 34ms/step - loss: 6.6801 - accuracy: 0.0411 - val_loss: 7.3618 - val_accuracy: 0.0348\n",
      "\n",
      "Epoch 00002: val_loss improved from 7.44031 to 7.36176, saving model to saved_models/weights.best.from_BatchNorm.hdf5\n",
      "Epoch 3/25\n",
      "3190/3190 [==============================] - 107s 34ms/step - loss: 6.2159 - accuracy: 0.0498 - val_loss: 7.5388 - val_accuracy: 0.0404\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 7.36176\n",
      "Epoch 4/25\n",
      "3190/3190 [==============================] - 108s 34ms/step - loss: 5.7904 - accuracy: 0.0545 - val_loss: 7.8569 - val_accuracy: 0.0423\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 7.36176\n",
      "Epoch 5/25\n",
      "3190/3190 [==============================] - 109s 34ms/step - loss: 5.3546 - accuracy: 0.0633 - val_loss: 8.2213 - val_accuracy: 0.0385\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 7.36176\n",
      "Epoch 6/25\n",
      "3190/3190 [==============================] - 109s 34ms/step - loss: 4.9221 - accuracy: 0.0727 - val_loss: 8.6240 - val_accuracy: 0.0367\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 7.36176\n",
      "Epoch 7/25\n",
      "3190/3190 [==============================] - 109s 34ms/step - loss: 4.4721 - accuracy: 0.1003 - val_loss: 8.9953 - val_accuracy: 0.0367\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 7.36176\n",
      "Epoch 8/25\n",
      "3190/3190 [==============================] - 108s 34ms/step - loss: 3.9519 - accuracy: 0.1755 - val_loss: 9.4556 - val_accuracy: 0.0320\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 7.36176\n",
      "Epoch 9/25\n",
      "3190/3190 [==============================] - 107s 34ms/step - loss: 3.4209 - accuracy: 0.2580 - val_loss: 10.5829 - val_accuracy: 0.0310\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 7.36176\n",
      "Epoch 10/25\n",
      "3190/3190 [==============================] - 107s 34ms/step - loss: 2.9003 - accuracy: 0.3511 - val_loss: 10.6389 - val_accuracy: 0.0244\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 7.36176\n",
      "Epoch 11/25\n",
      "3190/3190 [==============================] - 108s 34ms/step - loss: 2.4077 - accuracy: 0.4605 - val_loss: 11.4066 - val_accuracy: 0.0197\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 7.36176\n",
      "Epoch 12/25\n",
      "3190/3190 [==============================] - 108s 34ms/step - loss: 1.9566 - accuracy: 0.5652 - val_loss: 11.9917 - val_accuracy: 0.0216\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 7.36176\n",
      "Epoch 13/25\n",
      "3190/3190 [==============================] - 108s 34ms/step - loss: 1.6249 - accuracy: 0.6439 - val_loss: 12.3660 - val_accuracy: 0.0188\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 7.36176\n",
      "Epoch 14/25\n",
      "3190/3190 [==============================] - 108s 34ms/step - loss: 1.3546 - accuracy: 0.6959 - val_loss: 13.1396 - val_accuracy: 0.0207\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 7.36176\n",
      "Epoch 15/25\n",
      "3190/3190 [==============================] - 107s 34ms/step - loss: 1.1427 - accuracy: 0.7473 - val_loss: 13.2214 - val_accuracy: 0.0150\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 7.36176\n",
      "Epoch 16/25\n",
      "3190/3190 [==============================] - 107s 34ms/step - loss: 0.9838 - accuracy: 0.7724 - val_loss: 13.6801 - val_accuracy: 0.0179\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 7.36176\n",
      "Epoch 17/25\n",
      "3190/3190 [==============================] - 107s 34ms/step - loss: 0.8269 - accuracy: 0.8078 - val_loss: 14.4093 - val_accuracy: 0.0141\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 7.36176\n",
      "Epoch 18/25\n",
      "3190/3190 [==============================] - 107s 34ms/step - loss: 0.7076 - accuracy: 0.8470 - val_loss: 14.3214 - val_accuracy: 0.0169\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 7.36176\n",
      "Epoch 19/25\n",
      "3190/3190 [==============================] - 108s 34ms/step - loss: 0.6171 - accuracy: 0.8630 - val_loss: 14.2535 - val_accuracy: 0.0094\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 7.36176\n",
      "Epoch 20/25\n",
      "3190/3190 [==============================] - 108s 34ms/step - loss: 0.5298 - accuracy: 0.8796 - val_loss: 14.7122 - val_accuracy: 0.0150\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 7.36176\n",
      "Epoch 21/25\n",
      "3190/3190 [==============================] - 107s 34ms/step - loss: 0.4566 - accuracy: 0.8997 - val_loss: 15.4016 - val_accuracy: 0.0132\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 7.36176\n",
      "Epoch 22/25\n",
      "3190/3190 [==============================] - 107s 34ms/step - loss: 0.4168 - accuracy: 0.9116 - val_loss: 15.5634 - val_accuracy: 0.0160\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 7.36176\n",
      "Epoch 23/25\n",
      "3190/3190 [==============================] - 107s 34ms/step - loss: 0.3910 - accuracy: 0.9163 - val_loss: 15.6406 - val_accuracy: 0.0132\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 7.36176\n",
      "Epoch 24/25\n",
      "3190/3190 [==============================] - 108s 34ms/step - loss: 0.3455 - accuracy: 0.9238 - val_loss: 15.7749 - val_accuracy: 0.0150\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 7.36176\n",
      "Epoch 25/25\n",
      "3190/3190 [==============================] - 108s 34ms/step - loss: 0.3088 - accuracy: 0.9326 - val_loss: 15.7937 - val_accuracy: 0.0141\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 7.36176\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_BatchNorm.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "epochs_batch = 25\n",
    "\n",
    "hist_BN = modelBN.fit(np.squeeze(X_train), Y_train, validation_data=(np.squeeze(X_test), Y_test), \n",
    "epochs=epochs_batch, batch_size=32, callbacks=[checkpointer], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:1 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:2 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:3 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:4 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:5 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:6 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:7 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla K80, pci bus id: 0000:00:17.0, compute capability: 3.7\n",
      "/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: Tesla K80, pci bus id: 0000:00:18.0, compute capability: 3.7\n",
      "/job:localhost/replica:0/task:0/device:GPU:2 -> device: 2, name: Tesla K80, pci bus id: 0000:00:19.0, compute capability: 3.7\n",
      "/job:localhost/replica:0/task:0/device:GPU:3 -> device: 3, name: Tesla K80, pci bus id: 0000:00:1a.0, compute capability: 3.7\n",
      "/job:localhost/replica:0/task:0/device:GPU:4 -> device: 4, name: Tesla K80, pci bus id: 0000:00:1b.0, compute capability: 3.7\n",
      "/job:localhost/replica:0/task:0/device:GPU:5 -> device: 5, name: Tesla K80, pci bus id: 0000:00:1c.0, compute capability: 3.7\n",
      "/job:localhost/replica:0/task:0/device:GPU:6 -> device: 6, name: Tesla K80, pci bus id: 0000:00:1d.0, compute capability: 3.7\n",
      "/job:localhost/replica:0/task:0/device:GPU:7 -> device: 7, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBN.load_weights('saved_models/weights.best.from_BatchNorm.hdf5')\n",
    "\n",
    "landmark_pred = [np.argmax(modelBN.predict(np.expand_dims(tensor, axis=0))) for tensor in X_val]\n",
    "test_accuracy = np.sum(np.array(landmark_pred) == np.argmax(Y_val, axis=1)) / len(landmark_pred)\n",
    "print('Test accuracy:', test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=4.,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.5,\n",
    "    channel_shift_range=25,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "\n",
    "valid_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, Y_train, batch_size= 128)\n",
    "valid_generator = valid_datagen.flow(X_val, Y_val, batch_size= 128)\n",
    "epochs_aug = 50\n",
    "\n",
    "hist_aug = modelBN.fit_generator(train_generator, steps_per_epoch=6480//128, epochs=epochs_aug,\n",
    "                    validation_data=valid_generator, validation_steps=805//128,\n",
    "                    callbacks=[checkpointer], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transforms_672 = albumentations.Compose([\n",
    "    albumentations.Resize(672, 672),\n",
    "    albumentations.Normalize()\n",
    "])\n",
    "\n",
    "transforms_768 = albumentations.Compose([\n",
    "    albumentations.Resize(768, 768),\n",
    "    albumentations.Normalize()\n",
    "])\n",
    "transforms_512 = albumentations.Compose([\n",
    "    albumentations.Resize(512, 512),\n",
    "    albumentations.Normalize()\n",
    "])\n",
    "\n",
    "for row in os.listdir('outputs'):\n",
    "    image = cv2.imread(row)\n",
    "    image = image[:, :, ::-1]\n",
    "\n",
    "    res0 = self.transform672(image=image)\n",
    "    image0 = res0['image'].astype(np.float32)\n",
    "    image0 = image0.transpose(2, 0, 1)        \n",
    "\n",
    "    res1 = self.transform768(image=image)\n",
    "    image1 = res1['image'].astype(np.float32)\n",
    "    image1 = image1.transpose(2, 0, 1)    \n",
    "\n",
    "    res3 = self.transform512(image=image)\n",
    "    image3 = res3['image'].astype(np.float32)        \n",
    "    image3 = image3.transpose(2, 0, 1)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
